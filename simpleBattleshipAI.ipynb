{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simplified version of the game Battleship is used to train an agent using Reinforcement Learning. \n",
    "\n",
    "The board will consist of a single row with n columns, or squares. Only one ship is allowed and has a size of m<n squares. \n",
    "\n",
    "The expectation is for the agent to learn to\n",
    "a) fire at intervals of m squares (because a ship has a size of m squares and one would sample the space quicker this way), and\n",
    "b) fire at squares adjacent to the previous hit. \n",
    "\n",
    "We believe this policy minimizes the number of shots required to sink the ship. \n",
    "\n",
    "Once this is achieved, we will move on to more, larger ships, and a bigger board. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first develop the game engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Utility functions\n",
    "def genShipCoords(shipSize,minCoord,maxCoord):\n",
    "    coordinates = [0]*shipSize\n",
    "    coordinates[0] = random.randint(minCoord,maxCoord)\n",
    "    for i in range(1,shipSize):\n",
    "        coordinates[i] = coordinates[i-1] + 1 if coordinates[i-1] < maxCoord else coordinates[i-1]-1\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleBattleship(object):\n",
    "    \n",
    "    # Only a one-row board is implemented for now\n",
    "    def __init__(self, shipCoords, boardRows, boardCols):\n",
    "        self.shipCoords = shipCoords\n",
    "        self.boardSize = boardCols\n",
    "        self.board = np.zeros(boardCols) \n",
    "        \n",
    "    def fireShot(self, shotCoordinate):\n",
    "        if shotCoordinate>self.boardSize or shotCoordinate<0:\n",
    "            return 2\n",
    "        elif shotCoordinate in self.shipCoords:\n",
    "            # Hit\n",
    "            self.updateState(shotCoordinate)\n",
    "            return 1\n",
    "        else:\n",
    "            # Miss\n",
    "            return 0\n",
    "    def getState(self):\n",
    "        return self.board\n",
    "    \n",
    "    def updateState(self,coord):\n",
    "        self.board[coord] = 1\n",
    "    \n",
    "\n",
    "def randomAttacker():\n",
    "    shotsTaken = []\n",
    "    numShotsTaken = 0\n",
    "    numHits = 0\n",
    "    numMisses = 0\n",
    "    while True:\n",
    "        randomShot = random.randint(BOARD_SIZE[0], BOARD_SIZE[1])\n",
    "        #print(randomShot)\n",
    "\n",
    "        if randomShot in shotsTaken:\n",
    "            dummy=1\n",
    "            #print(\"INVALID\")\n",
    "        else:\n",
    "            numShotsTaken += 1\n",
    "            if attacker.fireShot(randomShot)==1:\n",
    "                #print(\"HIT\")\n",
    "                numHits += 1\n",
    "            else:\n",
    "                #print(\"MISS\")\n",
    "                numMisses += 1\n",
    "\n",
    "        shotsTaken.append(randomShot)\n",
    "\n",
    "        if numHits == 2 or numMisses==25:\n",
    "            break\n",
    "    return 100*numShotsTaken/BOARD_SIZE[1]\n",
    "\n",
    "    \n",
    "#     print(\"Number of shots taken:{}\".format(numShotsTaken))\n",
    "#     print(\"Number of misses:{}\".format(numMisses))\n",
    "#     print(\"% of board covered to sink ship:{}\".format(100*numShotsTaken/BOARD_SIZE[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Play a game\n",
    "BOARD_SIZE = (1,10)\n",
    "SHIP_SIZE = 2\n",
    "\n",
    "ship = genShipCoords(SHIP_SIZE, BOARD_SIZE[0], BOARD_SIZE[1])\n",
    "print(ship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the getState method in the simpleBattleShip class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "attacker = simpleBattleship(ship, BOARD_SIZE[0], BOARD_SIZE[1])\n",
    "attacker.fireShot(ship[0])\n",
    "print(attacker.getState())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg percentCovered was:73.066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGABJREFUeJzt3X+MXeV95/H3Z8exN6HBgJkgYpsdt560MmlDyshi1eyq\nWxdi0pShCj/MZhOncupKxUqy2+zu0BVsFxUJV2lJIyiSg904qMWmbrKZLm69BLNqWW0cjwkiGGIx\nMaa218DEuCZQGe+Qz/5xHycnN3fOHI9nPDDzeUlXc873POeZ59Gx5uNzzr3nyjYRERFj+WfTPYCI\niHhzS1BEREStBEVERNRKUERERK0ERURE1EpQRERErQRFRETUSlBEREStBEVERNSaM90DmAwXXnih\ne3p6pnsYERFvKXv27Pme7e7x2jUKCkkrgT8BuoD7bN/Ztn0e8GXgcuAocKPtA5KuBO4E5gIngf9o\ne2fZ53LgS8Dbge3Ap21b0gXAVqAHOADcYPtY3fh6enoYGhpqMpWIiCgkPd+k3biXniR1AfcAVwPL\ngJskLWtrtgY4ZnspcBewvtS/B/y67Z8HVgP3V/a5F/gtoLe8Vpb6APCI7V7gkbIeERHTpMk9iuXA\nsO39tk8CW4D+tjb9wOayvA1YIUm2v2X7/5b6XuDtkuZJuhg41/Y33Hoq4ZeBazv0tblSj4iIadAk\nKBYCByvrh0qtYxvbo8BxYEFbm48Aj9t+vbQ/NEafF9k+UpZfAC5qMMaIiJgiZ+VmtqRLaV2Ouup0\n9iv3LDo+B13SWmAtwCWXXHLGY4yIiM6anFEcBhZX1heVWsc2kuYA82nd1EbSIuCrwMdtf7fSftEY\nfb5YLk1Rfr7UaVC2N9jus93X3T3uTfuIiJigJkGxG+iVtETSXGAVMNjWZpDWzWqA64Cd5WzgPOAh\nYMD2/z7VuFxaekXSFZIEfBz4Woe+VlfqERExDcYNinLPYR2wA3gGeND2Xkm3S7qmNNsILJA0DPwH\nfvROpXXAUuA2SU+U17vKtt8B7gOGge8Cf1PqdwJXSnoW+NWyHhER00Qz4atQ+/r6nM9RREScHkl7\nbPeN1y6P8IiIiFoz4hEeERHTqWfgoWn73Qfu/LUp/x05o4iIiFoJioiIqJWgiIiIWgmKiIiolaCI\niIhaCYqIiKiVoIiIiFoJioiIqJWgiIiIWgmKiIiolaCIiIhaCYqIiKiVoIiIiFoJioiIqJWgiIiI\nWgmKiIio1SgoJK2UtE/SsKSBDtvnSdpatu+S1FPqCyQ9KulVSXdX2r+z8h3aT0j6nqTPl22fkDRS\n2fbJyZlqRERMxLjfcCepC7gHuBI4BOyWNGj76UqzNcAx20slrQLWAzcCJ4BbgfeWFwC2vw9cVvkd\ne4CvVPrbanvdhGcVERGTpskZxXJg2PZ+2yeBLUB/W5t+YHNZ3gaskCTbr9l+jFZgdCTpPcC7gL8/\n7dFHRMSUaxIUC4GDlfVDpdaxje1R4DiwoOEYVtE6g3Cl9hFJT0raJmlxw34iImIKvBluZq8CHqis\n/zXQY/sXgIf50ZnKj5G0VtKQpKGRkZGzMMyIiNmpSVAcBqr/q19Uah3bSJoDzAeOjtexpPcBc2zv\nOVWzfdT262X1PuDyTvva3mC7z3Zfd3d3g2lERMREjHszG9gN9EpaQisQVgH/tq3NILAa+D/AdcDO\ntktJY7mJHz+bQNLFto+U1WuAZxr0ExFBz8BD0z2EGWncoLA9KmkdsAPoAjbZ3ivpdmDI9iCwEbhf\n0jDwMq0wAUDSAeBcYK6ka4GrKu+YugH4UNuv/JSka4DR0tcnzmB+ERFxhpqcUWB7O7C9rXZbZfkE\ncP0Y+/bU9PvTHWq3ALc0GVdEREy9N8PN7IiIeBNLUERERK0ERURE1EpQRERErQRFRETUSlBERESt\nBEVERNRKUERERK0ERURE1Gr0yeyIiKbyvKWZJ2cUERFRK0ERERG1EhQREVErQREREbUSFBERUStB\nERERtRIUERFRq1FQSFopaZ+kYUkDHbbPk7S1bN8lqafUF0h6VNKrku5u2+d/lT6fKK931fUVERHT\nY9ygkNQF3ANcDSwDbpK0rK3ZGuCY7aXAXcD6Uj8B3Ap8dozuP2r7svJ6aZy+IiJiGjQ5o1gODNve\nb/sksAXob2vTD2wuy9uAFZJk+zXbj9EKjKY69nUa+0dExCRqEhQLgYOV9UOl1rGN7VHgOLCgQd9/\nVi473VoJg4n2FRERU2A6b2Z/1PbPA/+qvD52OjtLWitpSNLQyMjIlAwwIiKaBcVhYHFlfVGpdWwj\naQ4wHzha16ntw+Xn94G/oHWJq3FftjfY7rPd193d3WAaERExEU2CYjfQK2mJpLnAKmCwrc0gsLos\nXwfstO2xOpQ0R9KFZfltwIeBpybSV0RETK1xHzNue1TSOmAH0AVssr1X0u3AkO1BYCNwv6Rh4GVa\nYQKApAPAucBcSdcCVwHPAztKSHQBXwe+WHYZs6+IiDj7Gn0fhe3twPa22m2V5RPA9WPs2zNGt5eP\n0X7MviIi4uzLJ7MjIqJWgiIiImolKCIiola+Mztihsp3V8dkyRlFRETUSlBEREStBEVERNRKUERE\nRK0ERURE1EpQRERErQRFRETUSlBEREStBEVERNRKUERERK0ERURE1EpQRERErQRFRETUSlBERESt\nRkEhaaWkfZKGJQ102D5P0tayfZeknlJfIOlRSa9KurvS/h2SHpL0HUl7Jd1Z2fYJSSOSniivT575\nNCMiYqLGDQpJXcA9wNXAMuAmScvamq0BjtleCtwFrC/1E8CtwGc7dP052z8HvB/4JUlXV7ZttX1Z\ned13WjOKiIhJ1eSMYjkwbHu/7ZPAFqC/rU0/sLksbwNWSJLt12w/Riswfsj2P9l+tCyfBB4HFp3B\nPCIiYoo0CYqFwMHK+qFS69jG9ihwHFjQZACSzgN+HXikUv6IpCclbZO0uEk/ERExNab1ZrakOcAD\nwBds7y/lvwZ6bP8C8DA/OlNp33etpCFJQyMjI2dnwBERs1CToDgMVP9Xv6jUOrYpf/znA0cb9L0B\neNb2508VbB+1/XpZvQ+4vNOOtjfY7rPd193d3eBXRUTERDQJit1Ar6QlkuYCq4DBtjaDwOqyfB2w\n07brOpX0B7QC5TNt9Ysrq9cAzzQYY0RETJE54zWwPSppHbAD6AI22d4r6XZgyPYgsBG4X9Iw8DKt\nMAFA0gHgXGCupGuBq4BXgP8CfAd4XBLA3eUdTp+SdA0wWvr6xCTNNSIiJmDcoACwvR3Y3la7rbJ8\nArh+jH17xuhWY7S/BbilybgiImLq5ZPZERFRK0ERERG1EhQREVErQREREbUSFBERUavRu54iYmJ6\nBh6a7iFEnLGcUURERK0ERURE1EpQRERErQRFRETUSlBEREStBEVERNRKUERERK0ERURE1EpQRERE\nrQRFRETUSlBEREStBEVERNRqFBSSVkraJ2lY0kCH7fMkbS3bd0nqKfUFkh6V9Kqku9v2uVzSt8s+\nX1D54mxJF0h6WNKz5ef5Zz7NiIiYqHGDQlIXcA9wNbAMuEnSsrZma4BjtpcCdwHrS/0EcCvw2Q5d\n3wv8FtBbXitLfQB4xHYv8EhZj4iIadLkjGI5MGx7v+2TwBagv61NP7C5LG8DVkiS7ddsP0YrMH5I\n0sXAuba/YdvAl4FrO/S1uVKPiIhp0CQoFgIHK+uHSq1jG9ujwHFgwTh9Hhqjz4tsHynLLwAXdepA\n0lpJQ5KGRkZGGkwjIiIm4k19M7ucbXiMbRts99nu6+7uPssji4iYPZoExWFgcWV9Ual1bCNpDjAf\nODpOn4vG6PPFcmnq1CWqlxqMMSIipkiToNgN9EpaImkusAoYbGszCKwuy9cBO8vZQEfl0tIrkq4o\n73b6OPC1Dn2trtQjImIajPud2bZHJa0DdgBdwCbbeyXdDgzZHgQ2AvdLGgZephUmAEg6AJwLzJV0\nLXCV7aeB3wG+BLwd+JvyArgTeFDSGuB54IbJmGhEREzMuEEBYHs7sL2tdltl+QRw/Rj79oxRHwLe\n26F+FFjRZFwRETH13tQ3syMiYvolKCIiolaCIiIiaiUoIiKiVoIiIiJqJSgiIqJWgiIiImo1+hxF\nxFtdz8BD0z2EiLesnFFEREStBEVERNRKUERERK0ERURE1EpQRERErQRFRETUSlBEREStBEVERNRK\nUERERK1GQSFppaR9koYlDXTYPk/S1rJ9l6SeyrZbSn2fpA+W2s9KeqLyekXSZ8q235d0uLLtQ5Mz\n1YiImIhxH+EhqQu4B7gSOATsljRYvvf6lDXAMdtLJa0C1gM3SlpG6/uzLwXeDXxd0nts7wMuq/R/\nGPhqpb+7bH/uzKcXERFnqskZxXJg2PZ+2yeBLUB/W5t+YHNZ3gaskKRS32L7ddvPAcOlv6oVwHdt\nPz/RSURExNRpEhQLgYOV9UOl1rGN7VHgOLCg4b6rgAfaauskPSlpk6TzG4wxIiKmyLTezJY0F7gG\n+MtK+V7gZ2hdmjoC/NEY+66VNCRpaGRkZMrHGhExWzUJisPA4sr6olLr2EbSHGA+cLTBvlcDj9t+\n8VTB9ou237D9A+CL/OSlqlPtNtjus93X3d3dYBoRETERTYJiN9AraUk5A1gFDLa1GQRWl+XrgJ22\nXeqryruilgC9wDcr+91E22UnSRdXVn8DeKrpZCIiYvKN+64n26OS1gE7gC5gk+29km4HhmwPAhuB\n+yUNAy/TChNKuweBp4FR4GbbbwBIOofWO6l+u+1X/qGkywADBzpsj4iIs6jRN9zZ3g5sb6vdVlk+\nAVw/xr53AHd0qL9G64Z3e/1jTcYUERFnRz6ZHRERtRIUERFRK0ERERG1Gt2jiJgsPQMPTfcQIuI0\n5YwiIiJqJSgiIqJWgiIiImolKCIiolaCIiIiaiUoIiKiVoIiIiJqJSgiIqJWgiIiImolKCIiolaC\nIiIiaiUoIiKiVoIiIiJqJSgiIqJWo6CQtFLSPknDkgY6bJ8naWvZvktST2XbLaW+T9IHK/UDkr4t\n6QlJQ5X6BZIelvRs+Xn+mU0xIiLOxLhBIakLuAe4GlgG3CRpWVuzNcAx20uBu4D1Zd9lwCrgUmAl\n8Kelv1P+je3LbPdVagPAI7Z7gUfKekRETJMmZxTLgWHb+22fBLYA/W1t+oHNZXkbsEKSSn2L7ddt\nPwcMl/7qVPvaDFzbYIwRETFFmgTFQuBgZf1QqXVsY3sUOA4sGGdfA/9T0h5JayttLrJ9pCy/AFzU\nYIwRETFFpvOrUD9g+7CkdwEPS/qO7b+rNrBtSe60cwmXtQCXXHLJ1I82ImKWanJGcRhYXFlfVGod\n20iaA8wHjtbta/vUz5eAr/KjS1IvSrq49HUx8FKnQdneYLvPdl93d3eDaURExEQ0CYrdQK+kJZLm\n0ro5PdjWZhBYXZavA3badqmvKu+KWgL0At+UdI6kdwJIOge4CniqQ1+rga9NbGoRETEZxr30ZHtU\n0jpgB9AFbLK9V9LtwJDtQWAjcL+kYeBlWmFCafcg8DQwCtxs+w1JFwFfbd3vZg7wF7b/tvzKO4EH\nJa0BngdumMT5BtAz8NB0DyEi3kIa3aOwvR3Y3la7rbJ8Arh+jH3vAO5oq+0H3jdG+6PAiibjioiI\nqZdPZkdERK0ERURE1EpQRERErQRFRETUSlBEREStBEVERNRKUERERK0ERURE1EpQRERErQRFRETU\nSlBEREStBEVERNRKUERERK0ERURE1EpQRERErQRFRETUSlBEREStBEVERNRqFBSSVkraJ2lY0kCH\n7fMkbS3bd0nqqWy7pdT3SfpgqS2W9KikpyXtlfTpSvvfl3RY0hPl9aEzn2ZEREzUuN+ZLakLuAe4\nEjgE7JY0aPvpSrM1wDHbSyWtAtYDN0paBqwCLgXeDXxd0nuAUeB3bT8u6Z3AHkkPV/q8y/bnJmuS\nERExcU3OKJYDw7b32z4JbAH629r0A5vL8jZghSSV+hbbr9t+DhgGlts+YvtxANvfB54BFp75dCIi\nYrI1CYqFwMHK+iF+8o/6D9vYHgWOAwua7FsuU70f2FUpr5P0pKRNks7vNChJayUNSRoaGRlpMI2I\niJiIab2ZLemngL8CPmP7lVK+F/gZ4DLgCPBHnfa1vcF2n+2+7u7uszLeiIjZqElQHAYWV9YXlVrH\nNpLmAPOBo3X7SnobrZD4c9tfOdXA9ou237D9A+CLtC59RUTENGkSFLuBXklLJM2ldXN6sK3NILC6\nLF8H7LTtUl9V3hW1BOgFvlnuX2wEnrH9x9WOJF1cWf0N4KnTnVREREyecd/1ZHtU0jpgB9AFbLK9\nV9LtwJDtQVp/9O+XNAy8TCtMKO0eBJ6m9U6nm22/IekDwMeAb0t6ovyq37O9HfhDSZcBBg4Avz2J\n842IiNM0blAAlD/g29tqt1WWTwDXj7HvHcAdbbXHAI3R/mNNxhQREWdHo6CIqdEz8NB0DyEiYlx5\nhEdERNRKUERERK0ERURE1EpQRERErQRFRETUSlBEREStBEVERNRKUERERK0ERURE1EpQRERErQRF\nRETUSlBEREStBEVERNRKUERERK0ERURE1EpQRERErUZBIWmlpH2ShiUNdNg+T9LWsn2XpJ7KtltK\nfZ+kD47XZ/lu7l2lvrV8T3dEREyTcYNCUhdwD3A1sAy4SdKytmZrgGO2lwJ3AevLvstofX/2pcBK\n4E8ldY3T53rgrtLXsdJ3RERMkyZnFMuBYdv7bZ8EtgD9bW36gc1leRuwQpJKfYvt120/BwyX/jr2\nWfb5ldIHpc9rJz69iIg4U02CYiFwsLJ+qNQ6trE9ChwHFtTsO1Z9AfCPpY+xfldERJxFc6Z7ABMl\naS2wtqy+Kmnfaex+IfC9yR/Vm95snPdsnDPMznnPxjmj9Wc073/RpFGToDgMLK6sLyq1Tm0OSZoD\nzAeOjrNvp/pR4DxJc8pZRaffBYDtDcCGBuP/CZKGbPdNZN+3stk479k4Z5id856Nc4azM+8ml552\nA73l3Uhzad2cHmxrMwisLsvXATttu9RXlXdFLQF6gW+O1WfZ59HSB6XPr018ehERcabGPaOwPSpp\nHbAD6AI22d4r6XZgyPYgsBG4X9Iw8DKtP/yUdg8CTwOjwM223wDo1Gf5lf8Z2CLpD4Bvlb4jImKa\nqPWf+NlF0tpy6WpWmY3zno1zhtk579k4Zzg7856VQREREc3lER4REVFr1gXFeI8jmQkkLZb0qKSn\nJe2V9OlSv0DSw5KeLT/Pn+6xTrbyyf9vSfofZX3GPxJG0nmStkn6jqRnJP3LWXKs/3359/2UpAck\n/fOZdrwlbZL0kqSnKrWOx1YtXyhzf1LSL07WOGZVUDR8HMlMMAr8ru1lwBXAzWWeA8AjtnuBR8r6\nTPNp4JnK+mx4JMyfAH9r++eA99Ga/4w+1pIWAp8C+my/l9abYlYx8473l2g9/qhqrGN7Na13lvbS\n+ozZvZM1iFkVFDR7HMlbnu0jth8vy9+n9YdjIT/+qJUZ93gUSYuAXwPuK+sz/pEwkuYD/5ry7kDb\nJ23/IzP8WBdzgLeXz269AzjCDDvetv+O1jtJq8Y6tv3Al93yDVqfSbt4MsYx24KiyeNIZpTyJN/3\nA7uAi2wfKZteAC6apmFNlc8D/wn4QVmfDY+EWQKMAH9WLrndJ+kcZvixtn0Y+BzwD7QC4jiwh5l/\nvGHsYztlf99mW1DMKpJ+Cvgr4DO2X6luKx9unDFveZP0YeAl23umeyxn2RzgF4F7bb8feI22y0wz\n7VgDlOvy/bSC8t3AOfzkJZoZ72wd29kWFE0eRzIjSHobrZD4c9tfKeUXT52Klp8vTdf4psAvAddI\nOkDrkuKv0Lp2f165NAEz83gfAg7Z3lXWt9EKjpl8rAF+FXjO9ojt/wd8hda/gZl+vGHsYztlf99m\nW1A0eRzJW165Nr8ReMb2H1c2VR+1MqMej2L7FtuLbPfQOq47bX+UGf5IGNsvAAcl/WwpraD1JIQZ\ne6yLfwCukPSO8u/91Lxn9PEuxjq2g8DHy7ufrgCOVy5RnZFZ94E7SR+idS371KND7pjmIU06SR8A\n/h74Nj+6Xv97tO5TPAhcAjwP3GC7/UbZW56kXwY+a/vDkn6a1hnGBbQeCfPvbL8+neObbJIuo3UD\nfy6wH/hNWv8JnNHHWtJ/A26k9S6/bwGfpHVNfsYcb0kPAL9M68m4LwL/FfjvdDi2JTDvpnUJ7p+A\n37Q9NCnjmG1BERERp2e2XXqKiIjTlKCIiIhaCYqIiKiVoIiIiFoJioiIqJWgiIiIWgmKiIiolaCI\niIha/x/lIi3z8iVVhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106d35da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_EPISODES = 10000\n",
    "percentCovered = np.empty(NUM_EPISODES, dtype=int)\n",
    "\n",
    "for i in range(NUM_EPISODES):\n",
    "    percentCovered[i] = randomAttacker()\n",
    "    \n",
    "print(\"The avg percentCovered was:{}\".format(percentCovered.mean()))\n",
    "fig = plt.hist(percentCovered,normed=True,range=(1,100));\n",
    "attacker.getState()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a decent, simple battleship engine, let's focus on the reinforcement learning. \n",
    "\n",
    "The following algorithm is based on an actual Q-table. \n",
    "\n",
    "initialize Q[numstates,numactions] arbitrarily\n",
    "observe initial state s\n",
    "repeat\n",
    "    select and carry out an action a\n",
    "    observe reward r and new state s'\n",
    "    Q[s,a] = Q[s,a] + α(r + γmaxa' Q[s',a'] - Q[s,a])\n",
    "    s = s'\n",
    "until terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHIP LOCATION:[1, 2]\n",
      "random action is LEFT\n",
      "crosshair moved to -1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-602-528304083926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattacker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "#utility functions\n",
    "actionSetToStr = {-1:\"LEFT\",1:\"RIGHT\"}\n",
    "\n",
    "\n",
    "# ACTUAL TRAINING\n",
    "\n",
    "NUM_EPISODES = 10000\n",
    "BOARD_SIZE = (1,10)\n",
    "SHIP_SIZE = 2\n",
    "ship = genShipCoords(SHIP_SIZE, BOARD_SIZE[0], BOARD_SIZE[1])\n",
    "print(\"SHIP LOCATION:{}\".format(ship))\n",
    "attacker = simpleBattleship(ship, BOARD_SIZE[0], BOARD_SIZE[1])\n",
    "# let's assume we don't know the number of states\n",
    "Q  = {} #Q-table\n",
    "actionSet = (-1,1) #LEFT=-1, RIGHT= +1\n",
    "R = {1:1, 0:-1, 2:-100} #Reward function: +1 if HIT(1), -1 if MISS(0), -100 if INVALID(2)\n",
    "s = attacker.getState()\n",
    "crossHairCoord = 0 # agent starts w/ cross-hair at coordinate 0 \n",
    "for _ in range(2):\n",
    "    a = random.choice(actionSet)\n",
    "    print(\"random action is \" + actionSetToStr[a])\n",
    "    \n",
    "    crossHairCoord += a\n",
    "    print(\"crosshair moved to {}\".format(crossHairCoord))\n",
    "\n",
    "    r = R[attacker.fireShot(randomShot)]\n",
    "    s1 = attacker.getState()\n",
    "     \n",
    "    Q[s] = 1\n",
    "    print(r)\n",
    "    print(s1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One algorithm that uses rollouts is:\n",
    "\n",
    "initialize replay memory D\n",
    "initialize action-value function Q with random weights\n",
    "observe initial state s\n",
    "repeat\n",
    "    select an action a\n",
    "        with probability ε select a random action\n",
    "        otherwise select a = argmaxa’Q(s,a’)\n",
    "    carry out action a\n",
    "    observe reward r and new state s’\n",
    "    store experience <s, a, r, s’> in replay memory D\n",
    "\n",
    "    sample random transitions <ss, aa, rr, ss’> from replay memory D\n",
    "    calculate target for each minibatch transition\n",
    "        if ss’ is terminal state then tt = rr\n",
    "        otherwise tt = rr + γmaxa’Q(ss’, aa’)\n",
    "    train the Q network using (tt - Q(ss, aa))^2 as loss\n",
    "\n",
    "    s = s'\n",
    "until terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
