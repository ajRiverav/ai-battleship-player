{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simplified version of the game Battleship is used to train an agent using Reinforcement Learning. \n",
    "\n",
    "The board will consist of a single row with n columns, or squares. Only one ship is allowed and has a size of m<n squares. \n",
    "\n",
    "The expectation is for the agent to learn to\n",
    "a) fire at intervals of m squares (because a ship has a size of m squares and one would sample the space quicker this way), and\n",
    "b) fire at squares adjacent to the previous hit. \n",
    "\n",
    "We believe this policy minimizes the number of shots required to sink the ship. \n",
    "\n",
    "Once this is achieved, we will move on to more, larger ships, and a bigger board. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first develop the game engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def genShipCoords(shipLen,minCoord,maxCoord):\n",
    "    \"\"\"Generate ship coordinates randomly such all coordinates are in the mathematical range of [minCoord,maxCoord].\n",
    "    \n",
    "    Example: Assuming one wants the coordinates of a ship of length 3 on a board of size 10x1, one would\n",
    "    call the function: \n",
    "    ship = genShipCoords(3, 10, 1)\n",
    "    # ship returns a tuple with the coorindates (e.g. (3,4,5)\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: input validation on args\n",
    "    \n",
    "    # Get coords: we first get a random starting coordinate and then upon this, the rest of the coordinates \n",
    "    # are populated. \n",
    "    coordinates = [0]*shipLen #initialize \n",
    "    coordinates[0] = random.randint(minCoord,maxCoord) # return a random integer N such that a <= N <= b.\n",
    "    for i in range(1,shipLen):\n",
    "        if coordinates[i-1] < maxCoord:\n",
    "            coordinates[i] = coordinates[i-1] + 1\n",
    "        else: \n",
    "            coordinates[i] = coordinates[i-1] - 1\n",
    "                          \n",
    "    return tuple(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIT = \"HIT\"\n",
    "MISS = \"MISS\"\n",
    "SHOT_RESULT = {HIT: 1,\n",
    "               MISS: -1}\n",
    "\n",
    "class SimpleBattleship(object):\n",
    "    \n",
    "    # Only a one-row board is implemented for now\n",
    "    def __init__(self, shipCoords, boardRows, boardCols):\n",
    "        self.shipCoords = shipCoords\n",
    "        self.boardSize = boardCols\n",
    "        self.board = np.zeros(boardCols) \n",
    "        \n",
    "    def fireShot(self, shotCoordinate):\n",
    "        if shotCoordinate > self.boardSize or shotCoordinate < 1:\n",
    "            raise ValueError(\"Out of bounds: {}\".format(shotCoordinate))\n",
    "        \n",
    "        if shotCoordinate in self.shipCoords:\n",
    "            # Hit\n",
    "            self.updateState(shotCoordinate, SHOT_RESULT[HIT])\n",
    "            return SHOT_RESULT[HIT]\n",
    "        else:\n",
    "            # Miss\n",
    "            self.updateState(shotCoordinate, SHOT_RESULT[MISS])\n",
    "            return SHOT_RESULT[MISS]\n",
    "    def getState(self):\n",
    "        return self.board\n",
    "    \n",
    "    def updateState(self,coord,shotResult):\n",
    "        self.board[coord-1] = shotResult\n",
    "    \n",
    "    \n",
    "#     print(\"Number of shots taken:{}\".format(numShotsTaken))\n",
    "#     print(\"Number of misses:{}\".format(numMisses))\n",
    "#     print(\"% of board covered to sink ship:{}\".format(100*numShotsTaken/BOARD_SIZE[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the getState method in the simpleBattleShip class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 9)\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Play a game\n",
    "BOARD_ROWS = 1\n",
    "BOARD_COLS = 10\n",
    "SHIP_LEN = 2\n",
    "\n",
    "shipCoords = genShipCoords(SHIP_LEN, BOARD_ROWS, BOARD_COLS)\n",
    "print(shipCoords)\n",
    "\n",
    "gameTest = SimpleBattleship(shipCoords, BOARD_ROWS, BOARD_COLS) # place ship in the simple battleship game\n",
    "\n",
    "# fire shot at this known coordinate; must return a HIT because...well, it's a known coord. \n",
    "gameTest.fireShot(shipCoords[0]) \n",
    "print(game.getState()) # the state tells us if it was miss or not. \n",
    "\n",
    "# TODO: \n",
    "# fire shot at this known coordinate; must return a MISS because...well, it's a known coord. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg percentCovered was:73.077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def randomAttacker():\n",
    "    game = SimpleBattleship(shipCoords, BOARD_ROWS, BOARD_COLS)\n",
    "    shotsTaken = []\n",
    "    numShotsTaken = 0\n",
    "    numHits = 0\n",
    "    numMisses = 0\n",
    "    while True:\n",
    "        randomShot = random.randint(1,BOARD_COLS)\n",
    "        #print(randomShot)\n",
    "\n",
    "        if randomShot not in shotsTaken:\n",
    "            numShotsTaken += 1\n",
    "            shotsTaken.append(randomShot)\n",
    "            \n",
    "            if game.fireShot(randomShot)==SHOT_RESULT[HIT]:\n",
    "                #print(\"HIT\")\n",
    "                numHits += 1\n",
    "            else:\n",
    "                #print(\"MISS\")\n",
    "                numMisses += 1\n",
    "\n",
    "\n",
    "        if numHits == 2:\n",
    "            break\n",
    "    return 100*numShotsTaken/BOARD_COLS\n",
    "\n",
    "NUM_EPISODES = 10000\n",
    "percentCovered = np.empty(NUM_EPISODES, dtype=int)\n",
    "\n",
    "for i in range(NUM_EPISODES):\n",
    "    percentCovered[i] = randomAttacker()\n",
    "    \n",
    "print(\"The avg percentCovered was:{}\".format(percentCovered.mean()))\n",
    "## fig = plt.hist(percentCovered,normed=True,range=(1,100)); failed last time\n",
    "fig = plt.hist(percentCovered,range=(1,100));\n",
    "game.getState()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a decent, simple battleship engine, let's focus on the reinforcement learning. \n",
    "\n",
    "The following algorithm is based on an actual Q-table. \n",
    "\n",
    "initialize Q[numstates,numactions] arbitrarily\n",
    "observe initial state s\n",
    "repeat\n",
    "    select and carry out an action a\n",
    "    observe reward r and new state s'\n",
    "    Q[s,a] = Q[s,a] + α(r + γmaxa' Q[s',a'] - Q[s,a])\n",
    "    s = s'\n",
    "until terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #utility functions\n",
    "# actionSetToStr = {-1:\"LEFT\",1:\"RIGHT\"}\n",
    "\n",
    "\n",
    "# # ACTUAL TRAINING\n",
    "\n",
    "# NUM_EPISODES = 10000\n",
    "# BOARD_SIZE = (1,10)\n",
    "# SHIP_SIZE = 2\n",
    "# ship = genShipCoords(SHIP_SIZE, BOARD_ROWS, BOARD_COLS)\n",
    "# print(\"SHIP LOCATION:{}\".format(ship))\n",
    "# attacker = SimpleBattleship(ship, BOARD_ROWS, BOARD_COLS)\n",
    "# # let's assume we don't know the number of states\n",
    "# Q  = {} #Q-table\n",
    "# actionSet = (-1,1) #LEFT=-1, RIGHT= +1\n",
    "# R = {1:1, 0:-1, 2:-100} #Reward function: +1 if HIT(1), -1 if MISS(0), -100 if INVALID(2)\n",
    "# s = attacker.getState()\n",
    "# crossHairCoord = 0 # agent starts w/ cross-hair at coordinate 0 \n",
    "# for _ in range(2):\n",
    "#     a = random.choice(actionSet)\n",
    "#     print(\"random action is \" + actionSetToStr[a])\n",
    "    \n",
    "#     crossHairCoord += a\n",
    "#     print(\"crosshair moved to {}\".format(crossHairCoord))\n",
    "\n",
    "#     r = R[attacker.fireShot(randomShot)]\n",
    "#     s1 = attacker.getState()\n",
    "     \n",
    "#     Q[s] = 1\n",
    "#     print(r)\n",
    "#     print(s1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One algorithm that uses rollouts is:\n",
    "\n",
    "initialize replay memory D\n",
    "initialize action-value function Q with random weights\n",
    "observe initial state s\n",
    "repeat\n",
    "    select an action a\n",
    "        with probability ε select a random action\n",
    "        otherwise select a = argmaxa’Q(s,a’)\n",
    "    carry out action a\n",
    "    observe reward r and new state s’\n",
    "    store experience <s, a, r, s’> in replay memory D\n",
    "\n",
    "    sample random transitions <ss, aa, rr, ss’> from replay memory D\n",
    "    calculate target for each minibatch transition\n",
    "        if ss’ is terminal state then tt = rr\n",
    "        otherwise tt = rr + γmaxa’Q(ss’, aa’)\n",
    "    train the Q network using (tt - Q(ss, aa))^2 as loss\n",
    "\n",
    "    s = s'\n",
    "until terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
